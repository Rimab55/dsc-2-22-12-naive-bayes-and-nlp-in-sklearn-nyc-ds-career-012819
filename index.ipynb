{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes and Scikit-Learn - Codealong \n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lesson, we'll gain experience using sklearn to work with text data and implement a Naive Bayesian Classifier, including sklearn pipelines!\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Implement Basic NLP Tasks including stemming/lemmatization, tokenization, and word vectorization\n",
    "* Implement a machine learning classifier to process text, run the classifier, and validate results \n",
    "\n",
    "## Getting Started\n",
    "\n",
    "In this lesson, we'll see an example of how we can we can use professsional tools such as sklearn to work through a real world NLP task. For this lesson, we'll build a pipeline that processes the text and then trains a Naive Bayesian Classifier on the _Reuters dataset_.  This tutorial has been modified from the tutorial available in the [sklearn documentation](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html).\n",
    "## Loading Our Dataset\n",
    "\n",
    "We need to start by loading in our dataset.  SKlearn has provided a helper file to do this for us, called `fetch_data.py`.  \n",
    "\n",
    "To load the data:\n",
    "\n",
    "1. Open a terminal window\n",
    "2. Navigate to this directory\n",
    "3. Run the command `python fetch_data.py`\n",
    "\n",
    "**_NOTE:_** This dataset is decent size, coming it at ~14 mb compressed.  This helper file will download the file and then decompress the data, but will only update you as each step finishes.  If it seems like it's frozen, don't worry--just let it finish! It should take a few minutes. \n",
    "\n",
    "When the helper file has finished, you'll see two new folders in this directory--`20news-bydate-test` and `20news-bydate-train`.\n",
    "\n",
    "In order to make things move a bit more quickly, we'll limit ourselves to only 4 of the available 20 categories.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python fetch_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll load in only the files that contains articles matching those categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, \n",
    "                                  shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the names of our targets to confirm that we have the right ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's take a look at how many articles we have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2257"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: sd345@city.ac.uk (Michael Collier)\\nSubject: Converting images to HP LaserJet III?\\nNntp-Posting-Host: hampton\\nOrganization: The City University\\nLines: 14\\n\\nDoes anyone know of a good way (standard PC application/PD utility) to\\nconvert tif/img/tga files into LaserJet III format.  We would also like to\\ndo the same, converting to HPGL (HP plotter) files.\\n\\nPlease email any response.\\n\\nIs this the correct group?\\n\\nThanks in advance.  Michael.\\n-- \\nMichael Collier (Programmer)                 The Computer Unit,\\nEmail: M.P.Collier@uk.ac.city                The City University,\\nTel: 071 477-8000 x3769                      London,\\nFax: 071 477-8565                            EC1V 0HB.\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even take a look at the filenames of the articles, and the articles themselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First line of article\n",
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n"
     ]
    }
   ],
   "source": [
    "print(\"First line of article\")\n",
    "print('\\n'.join(twenty_train.data[0].split('\\n')[:3]))   # 3 first lines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: comp.graphics\n"
     ]
    }
   ],
   "source": [
    "print('label: {}'.format(twenty_train.target_names[twenty_train.target[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comp.graphics'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also a good habit to inspect our labels to get a feel for what they look like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3, 3, 3, 3, 3, 2, 2, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data, we can move onto preprocessing our text, which includes:\n",
    "\n",
    "* Tokenizing our text\n",
    "* Transforming our text to a vectorized format\n",
    "\n",
    "Run the cell below to import everything we'll need for the remainder of this lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "np.random.seed(0)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing Our Text\n",
    "\n",
    "Now that we've loaded in the data, all that's left to do is to vectorize it, so that we can use it to train a **_Multinomial Naive Bayesian Classifier_**.\n",
    "\n",
    "We'll start by using **Count Vectorization_** and then convert everything to **_Term Frequencies_** to normalize everything (otherwise, longer articles would naturally have higher word counts than shorter articles). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "x_train_counts = count_vectorizer.fit_transform(twenty_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2257"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2257 emails\n",
    "\n",
    "len(twenty_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2257x35788 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 365886 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function fit_transform in module sklearn.feature_extraction.text:\n",
      "\n",
      "fit_transform(self, raw_documents, y=None)\n",
      "    Learn the vocabulary dictionary and return term-document matrix.\n",
      "    \n",
      "    This is equivalent to fit followed by transform, but more efficiently\n",
      "    implemented.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    raw_documents : iterable\n",
      "        An iterable which yields either str, unicode or file objects.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    X : array, [n_samples, n_features]\n",
      "        Document-term matrix.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(CountVectorizer.fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'from': 14887,\n",
       " 'sd345': 29022,\n",
       " 'city': 8696,\n",
       " 'ac': 4017,\n",
       " 'uk': 33256,\n",
       " 'michael': 21661,\n",
       " 'collier': 9031,\n",
       " 'subject': 31077,\n",
       " 'converting': 9805,\n",
       " 'images': 17366,\n",
       " 'to': 32493,\n",
       " 'hp': 16916,\n",
       " 'laserjet': 19780,\n",
       " 'iii': 17302,\n",
       " 'nntp': 23122,\n",
       " 'posting': 25663,\n",
       " 'host': 16881,\n",
       " 'hampton': 16082,\n",
       " 'organization': 23915,\n",
       " 'the': 32142,\n",
       " 'university': 33597,\n",
       " 'lines': 20253,\n",
       " '14': 587,\n",
       " 'does': 12051,\n",
       " 'anyone': 5201,\n",
       " 'know': 19458,\n",
       " 'of': 23610,\n",
       " 'good': 15576,\n",
       " 'way': 34755,\n",
       " 'standard': 30623,\n",
       " 'pc': 24651,\n",
       " 'application': 5285,\n",
       " 'pd': 24677,\n",
       " 'utility': 33915,\n",
       " 'convert': 9801,\n",
       " 'tif': 32391,\n",
       " 'img': 17389,\n",
       " 'tga': 32116,\n",
       " 'files': 14281,\n",
       " 'into': 18268,\n",
       " 'format': 14676,\n",
       " 'we': 34775,\n",
       " 'would': 35312,\n",
       " 'also': 4808,\n",
       " 'like': 20198,\n",
       " 'do': 12014,\n",
       " 'same': 28619,\n",
       " 'hpgl': 16927,\n",
       " 'plotter': 25361,\n",
       " 'please': 25337,\n",
       " 'email': 12833,\n",
       " 'any': 5195,\n",
       " 'response': 27836,\n",
       " 'is': 18474,\n",
       " 'this': 32270,\n",
       " 'correct': 9932,\n",
       " 'group': 15837,\n",
       " 'thanks': 32135,\n",
       " 'in': 17556,\n",
       " 'advance': 4378,\n",
       " 'programmer': 26175,\n",
       " 'computer': 9338,\n",
       " 'unit': 33572,\n",
       " 'tel': 31915,\n",
       " '071': 177,\n",
       " '477': 2326,\n",
       " '8000': 3062,\n",
       " 'x3769': 35416,\n",
       " 'london': 20459,\n",
       " 'fax': 14085,\n",
       " '8565': 3166,\n",
       " 'ec1v': 12541,\n",
       " '0hb': 230,\n",
       " 'ani': 5046,\n",
       " 'ms': 22366,\n",
       " 'uky': 33267,\n",
       " 'edu': 12626,\n",
       " 'aniruddha': 5062,\n",
       " 'deglurkar': 11001,\n",
       " 'help': 16418,\n",
       " 'splitting': 30464,\n",
       " 'trimming': 32915,\n",
       " 'region': 27378,\n",
       " 'along': 4788,\n",
       " 'mesh': 21550,\n",
       " 'kentucky': 19254,\n",
       " 'dept': 11193,\n",
       " 'math': 21153,\n",
       " 'sciences': 28899,\n",
       " '28': 1731,\n",
       " 'hi': 16550,\n",
       " 'have': 16254,\n",
       " 'problem': 26093,\n",
       " 'hope': 16833,\n",
       " 'some': 30173,\n",
       " 'gurus': 15949,\n",
       " 'can': 7766,\n",
       " 'me': 21322,\n",
       " 'solve': 30164,\n",
       " 'background': 6031,\n",
       " 'rectangular': 27238,\n",
       " 'uv': 33949,\n",
       " 'domain': 12075,\n",
       " 'mapping': 20985,\n",
       " '3d': 2148,\n",
       " 'bezier': 6574,\n",
       " 'patch': 24567,\n",
       " '2d': 1858,\n",
       " 'area': 5411,\n",
       " 'which': 34954,\n",
       " 'inside': 18016,\n",
       " 'loop': 20480,\n",
       " 'had': 16014,\n",
       " 'be': 6298,\n",
       " 'rendered': 27582,\n",
       " 'set': 29313,\n",
       " 'curve': 10471,\n",
       " 'segments': 29147,\n",
       " 'for': 14601,\n",
       " 'sake': 28580,\n",
       " 'notation': 23256,\n",
       " 'made': 20770,\n",
       " 'up': 33773,\n",
       " 'cells': 8153,\n",
       " 'my': 22541,\n",
       " 'has': 16216,\n",
       " 'split': 30462,\n",
       " 'individual': 17716,\n",
       " 'smaller': 29976,\n",
       " 'bounded': 7085,\n",
       " 'by': 7505,\n",
       " 'if': 17268,\n",
       " 'cell': 8150,\n",
       " 'wholly': 34992,\n",
       " 'then': 32164,\n",
       " 'it': 18551,\n",
       " 'output': 24079,\n",
       " 'as': 5549,\n",
       " 'whole': 34987,\n",
       " 'else': 12817,\n",
       " 'trivially': 32945,\n",
       " 'rejected': 27438,\n",
       " 'body': 6939,\n",
       " 'how': 16908,\n",
       " 'thiss': 32271,\n",
       " 'done': 12103,\n",
       " 'or': 23870,\n",
       " 'there': 32202,\n",
       " 'algo': 4687,\n",
       " 'somewhere': 30194,\n",
       " 'doing': 12065,\n",
       " 'appreciated': 5304,\n",
       " 'get': 15319,\n",
       " 'irritated': 18465,\n",
       " 'human': 16999,\n",
       " 'stay': 30701,\n",
       " 'cool': 9839,\n",
       " 'divine': 11944,\n",
       " 'djohnson': 11966,\n",
       " 'cs': 10324,\n",
       " 'ucsd': 33216,\n",
       " 'darin': 10667,\n",
       " 'johnson': 18893,\n",
       " 're': 27031,\n",
       " 'harrassed': 16194,\n",
       " 'at': 5698,\n",
       " 'work': 35255,\n",
       " 'could': 9992,\n",
       " 'use': 33858,\n",
       " 'prayers': 25765,\n",
       " 'cse': 10339,\n",
       " 'san': 28631,\n",
       " 'diego': 11499,\n",
       " '63': 2648,\n",
       " 'well': 34866,\n",
       " 'll': 20373,\n",
       " 'but': 7480,\n",
       " 'may': 21209,\n",
       " 'apply': 5289,\n",
       " 'other': 24020,\n",
       " 'people': 24784,\n",
       " 'so': 30068,\n",
       " 'post': 25646,\n",
       " 've': 34120,\n",
       " 'been': 6358,\n",
       " 'working': 35264,\n",
       " 'company': 9191,\n",
       " 'eight': 12703,\n",
       " 'years': 35587,\n",
       " 'various': 34083,\n",
       " 'engineering': 13051,\n",
       " 'jobs': 18863,\n",
       " 'female': 14166,\n",
       " 'yesterday': 35603,\n",
       " 'counted': 10004,\n",
       " 'and': 4992,\n",
       " 'realized': 27084,\n",
       " 'that': 32139,\n",
       " 'on': 23733,\n",
       " 'seven': 29333,\n",
       " 'different': 11520,\n",
       " 'occasions': 23548,\n",
       " 'sexually': 29352,\n",
       " 'dreaded': 12231,\n",
       " 'coming': 9110,\n",
       " 'back': 6024,\n",
       " 'today': 32506,\n",
       " 'what': 34923,\n",
       " 'boss': 7056,\n",
       " 'comes': 9098,\n",
       " 'ask': 5578,\n",
       " 'kind': 19370,\n",
       " 'question': 26709,\n",
       " 'your': 35648,\n",
       " 'should': 29578,\n",
       " 'person': 24895,\n",
       " 'bring': 7231,\n",
       " 'these': 32221,\n",
       " 'problems': 26097,\n",
       " 'he': 16302,\n",
       " 'she': 29455,\n",
       " 'not': 23250,\n",
       " 'seem': 29130,\n",
       " 'take': 31710,\n",
       " 'action': 4194,\n",
       " 'keep': 19210,\n",
       " 'going': 15545,\n",
       " 'higher': 16573,\n",
       " 'sexual': 29350,\n",
       " 'harrassment': 16195,\n",
       " 'need': 22774,\n",
       " 'tolerated': 32530,\n",
       " 'an': 4938,\n",
       " 'enormous': 13089,\n",
       " 'emotional': 12899,\n",
       " 'support': 31364,\n",
       " 'discuss': 11723,\n",
       " 'with': 35157,\n",
       " 'someone': 30180,\n",
       " 'they': 32233,\n",
       " 'are': 5410,\n",
       " 'trying': 32997,\n",
       " 'something': 30187,\n",
       " 'about': 3958,\n",
       " 'you': 35638,\n",
       " 'feel': 14135,\n",
       " 'perhaps': 24827,\n",
       " 'personnel': 24908,\n",
       " 'department': 11159,\n",
       " 'while': 34956,\n",
       " 'preserving': 25924,\n",
       " 'privacy': 26060,\n",
       " 'most': 22270,\n",
       " 'companies': 9188,\n",
       " 'will': 35057,\n",
       " 'want': 34660,\n",
       " 'deal': 10797,\n",
       " 'because': 6333,\n",
       " 'constant': 9614,\n",
       " 'anxiety': 5193,\n",
       " 'seriously': 29286,\n",
       " 'affect': 4431,\n",
       " 'effectively': 12659,\n",
       " 'employees': 12924,\n",
       " 'their': 32152,\n",
       " 'unclear': 33374,\n",
       " 'letter': 20054,\n",
       " 'inconceivable': 17622,\n",
       " 'management': 20906,\n",
       " 'remains': 27528,\n",
       " 'ignorant': 17283,\n",
       " 'employee': 12923,\n",
       " 'strife': 30973,\n",
       " 'even': 13491,\n",
       " 'after': 4471,\n",
       " 'miracle': 21859,\n",
       " 'notice': 23268,\n",
       " 'manager': 20907,\n",
       " 'did': 11493,\n",
       " 'attention': 5783,\n",
       " 'ups': 33807,\n",
       " 'indeed': 17666,\n",
       " 'ignore': 17287,\n",
       " 'entire': 13132,\n",
       " 'state': 30673,\n",
       " 'agency': 4496,\n",
       " 'willing': 35073,\n",
       " 'fight': 14265,\n",
       " 'check': 8380,\n",
       " 'lawyer': 19852,\n",
       " 'women': 35216,\n",
       " 'resource': 27816,\n",
       " 'center': 8159,\n",
       " 'etc': 13400,\n",
       " 'find': 14309,\n",
       " 'out': 24052,\n",
       " 'paster': 24555,\n",
       " 'priest': 26010,\n",
       " 'husband': 17055,\n",
       " 'judgemental': 19017,\n",
       " 'supportive': 31370,\n",
       " 'comforting': 9106,\n",
       " 'lot': 20517,\n",
       " 'healing': 16325,\n",
       " 'returned': 27926,\n",
       " '11': 336,\n",
       " '25': 1632,\n",
       " 'only': 23757,\n",
       " 'ever': 13503,\n",
       " 'single': 29769,\n",
       " 'already': 4805,\n",
       " 'left': 19951,\n",
       " 'lunch': 20631,\n",
       " '15': 677,\n",
       " 'no': 23123,\n",
       " 'one': 23741,\n",
       " 'bothered': 7065,\n",
       " 'call': 7714,\n",
       " 'building': 7391,\n",
       " 'though': 32297,\n",
       " 'number': 23363,\n",
       " 'was': 34703,\n",
       " 'posted': 25654,\n",
       " 'happens': 16136,\n",
       " 'honest': 16803,\n",
       " 'believe': 6430,\n",
       " 'due': 12354,\n",
       " 'gross': 15827,\n",
       " 'insensitivity': 18009,\n",
       " 'feelings': 14138,\n",
       " 'through': 32332,\n",
       " 'offices': 23636,\n",
       " 'tend': 31978,\n",
       " 'more': 22215,\n",
       " 'insensitive': 18008,\n",
       " 'than': 32131,\n",
       " 'normally': 23215,\n",
       " 'maybe': 21212,\n",
       " 'hustle': 17068,\n",
       " 'stress': 30954,\n",
       " 'happen': 16131,\n",
       " 'often': 23654,\n",
       " 'didn': 11495,\n",
       " 'realize': 27083,\n",
       " 'car': 7860,\n",
       " 'broken': 7265,\n",
       " 'come': 9093,\n",
       " 'wonder': 35218,\n",
       " 'why': 35006,\n",
       " 'go': 15511,\n",
       " 'make': 20862,\n",
       " 'stop': 30874,\n",
       " 'being': 6412,\n",
       " 'angry': 5041,\n",
       " 'ignored': 17288,\n",
       " 'laugh': 19819,\n",
       " 'once': 23736,\n",
       " 'went': 34876,\n",
       " 'off': 23614,\n",
       " 'without': 35168,\n",
       " 'our': 24046,\n",
       " 'who': 34982,\n",
       " 'paying': 24636,\n",
       " 'reason': 27103,\n",
       " 'mr': 22356,\n",
       " 'moderator': 22069,\n",
       " 'allows': 4766,\n",
       " 'latest': 19802,\n",
       " 'indulgence': 17737,\n",
       " 'turn': 33078,\n",
       " 'signs': 29690,\n",
       " 'age': 4492,\n",
       " 'closing': 8860,\n",
       " 'don': 12096,\n",
       " 'let': 20048,\n",
       " 'hateful': 16235,\n",
       " 'actions': 4195,\n",
       " 'harm': 16179,\n",
       " 'still': 30808,\n",
       " 'playground': 25324,\n",
       " 'bully': 7413,\n",
       " 'enjoy': 13068,\n",
       " 'seeing': 29124,\n",
       " 'hurt': 17050,\n",
       " 'cause': 8034,\n",
       " 'accept': 4039,\n",
       " 'opinions': 23815,\n",
       " 'imbecile': 17384,\n",
       " 'worthless': 35306,\n",
       " 'much': 22403,\n",
       " 'wiser': 35145,\n",
       " 'hold': 16743,\n",
       " 'great': 15743,\n",
       " 'esteem': 13379,\n",
       " 'luxury': 20663,\n",
       " 'day': 10752,\n",
       " 'bytes': 7517,\n",
       " 'swap': 31497,\n",
       " 's0612596': 28498,\n",
       " 'rug': 28425,\n",
       " 'nl': 23102,\n",
       " 'zwart': 35780,\n",
       " 'catholic': 8017,\n",
       " 'church': 8609,\n",
       " 'poland': 25461,\n",
       " 'faculteit': 13921,\n",
       " 'der': 11198,\n",
       " 'letteren': 20056,\n",
       " 'rijksuniversiteit': 28104,\n",
       " 'groningen': 15824,\n",
       " '10': 242,\n",
       " 'hello': 16413,\n",
       " 'writing': 35351,\n",
       " 'paper': 24382,\n",
       " 'role': 28256,\n",
       " '1989': 1097,\n",
       " 'tell': 31945,\n",
       " 'fill': 14285,\n",
       " 'recent': 27149,\n",
       " 'books': 7008,\n",
       " 'articles': 5530,\n",
       " 'english': 13055,\n",
       " 'german': 15305,\n",
       " 'french': 14842,\n",
       " 'important': 17508,\n",
       " 'concerning': 9379,\n",
       " 'abortion': 3954,\n",
       " 'law': 19841,\n",
       " 'religious': 27510,\n",
       " 'education': 12629,\n",
       " 'schools': 28877,\n",
       " 'birth': 6726,\n",
       " 'control': 9771,\n",
       " 'relation': 27456,\n",
       " 'government': 15618,\n",
       " 'thanx': 32138,\n",
       " 'masja': 21101,\n",
       " 'stanly': 30638,\n",
       " 'grok11': 15822,\n",
       " 'columbiasc': 9067,\n",
       " 'ncr': 22725,\n",
       " 'com': 9072,\n",
       " 'elder': 12731,\n",
       " 'brother': 7280,\n",
       " 'corp': 9925,\n",
       " 'columbia': 9066,\n",
       " 'sc': 28771,\n",
       " 'article': 5529,\n",
       " 'apr': 5340,\n",
       " '00': 0,\n",
       " '57': 2521,\n",
       " '41': 2203,\n",
       " '1993': 1102,\n",
       " '28246': 1742,\n",
       " 'athos': 5730,\n",
       " 'rutgers': 28473,\n",
       " 'rexlex': 27997,\n",
       " 'fnal': 14526,\n",
       " 'gov': 15612,\n",
       " 'writes': 35350,\n",
       " '01': 37,\n",
       " '56': 2513,\n",
       " '22824': 1540,\n",
       " 'shrum': 29610,\n",
       " 'hpfcso': 16926,\n",
       " 'fc': 14095,\n",
       " 'matt': 21176,\n",
       " '22': 1490,\n",
       " 'therefore': 32205,\n",
       " 'main': 20842,\n",
       " 'highways': 16585,\n",
       " 'many': 20978,\n",
       " 'invite': 18363,\n",
       " 'wedding': 34810,\n",
       " 'feast': 14109,\n",
       " 'hmmmmmm': 16703,\n",
       " 'sounds': 30250,\n",
       " 'theology': 32179,\n",
       " 'christ': 8544,\n",
       " 'odds': 23595,\n",
       " 'am': 4852,\n",
       " 'parable': 24395,\n",
       " 'jesus': 18774,\n",
       " 'tells': 31948,\n",
       " 'kingdom': 19383,\n",
       " 'heaven': 16358,\n",
       " 'unto': 33741,\n",
       " 'certain': 8197,\n",
       " 'king': 19382,\n",
       " 'marriage': 21060,\n",
       " 'his': 16642,\n",
       " 'son': 30199,\n",
       " 'clothes': 8863,\n",
       " 'were': 34879,\n",
       " 'customary': 10481,\n",
       " 'given': 15406,\n",
       " 'those': 32295,\n",
       " 'chose': 8525,\n",
       " 'attend': 5777,\n",
       " 'man': 20903,\n",
       " 'refused': 27352,\n",
       " 'wear': 34790,\n",
       " 'equalivant': 13239,\n",
       " 'righteousness': 28091,\n",
       " 'when': 34935,\n",
       " 'died': 11498,\n",
       " 'sins': 29785,\n",
       " 'provided': 26356,\n",
       " 'decision': 10874,\n",
       " 'put': 26570,\n",
       " 'vbv': 34111,\n",
       " 'lor': 20493,\n",
       " 'eeap': 12639,\n",
       " 'cwru': 10510,\n",
       " 'virgilio': 34360,\n",
       " 'dean': 10805,\n",
       " 'velasco': 34151,\n",
       " 'jr': 18983,\n",
       " 'arrogance': 5512,\n",
       " 'christians': 8559,\n",
       " 'case': 7965,\n",
       " 'western': 34896,\n",
       " 'reserve': 27768,\n",
       " 'univ': 33581,\n",
       " 'cleveland': 8795,\n",
       " 'ohio': 23662,\n",
       " 'usa': 33848,\n",
       " '2073': 1396,\n",
       " 'geneva': 15237,\n",
       " 'hayesstw': 16277,\n",
       " 'risc1': 28131,\n",
       " 'unisa': 33569,\n",
       " 'za': 35688,\n",
       " 'steve': 30776,\n",
       " 'hayes': 16276,\n",
       " 'similar': 29715,\n",
       " 'analogy': 4953,\n",
       " 'might': 21732,\n",
       " 'medical': 21386,\n",
       " 'doctor': 12026,\n",
       " 'believes': 6437,\n",
       " 'blood': 6863,\n",
       " 'transfusion': 32756,\n",
       " 'necessary': 22765,\n",
       " 'save': 28735,\n",
       " 'life': 20167,\n",
       " 'child': 8451,\n",
       " 'whose': 34999,\n",
       " 'parents': 24451,\n",
       " 'jehovah': 18729,\n",
       " 'witnesses': 35176,\n",
       " 'conscientious': 9557,\n",
       " 'objections': 23477,\n",
       " 'efforts': 12669,\n",
       " 'persuade': 24913,\n",
       " 'them': 32160,\n",
       " 'agree': 4529,\n",
       " 'perceived': 24793,\n",
       " 'arrogant': 5513,\n",
       " 'precisely': 25794,\n",
       " 'truth': 32989,\n",
       " 'otherwise': 24026,\n",
       " 'belief': 6426,\n",
       " 'irrelevant': 18452,\n",
       " 'here': 16482,\n",
       " 'matters': 21179,\n",
       " 'true': 32973,\n",
       " 'seen': 29135,\n",
       " 'foce': 14533,\n",
       " 'beliefs': 6427,\n",
       " 'carry': 7938,\n",
       " 'step': 30747,\n",
       " 'further': 15006,\n",
       " 'doctors': 12028,\n",
       " 'claim': 8713,\n",
       " 'infallible': 17784,\n",
       " 'generally': 15219,\n",
       " 'admit': 4330,\n",
       " 'conceivably': 9360,\n",
       " 'wrong': 35358,\n",
       " 'tranfusion': 32722,\n",
       " 'all': 4720,\n",
       " 'however': 16913,\n",
       " 'enough': 13091,\n",
       " 'confidence': 9461,\n",
       " 'conviction': 9816,\n",
       " 'genuine': 15261,\n",
       " 'concern': 9377,\n",
       " 'fallible': 13977,\n",
       " 'beings': 6413,\n",
       " 'must': 22509,\n",
       " 'acknowledge': 4153,\n",
       " 'possibility': 25640,\n",
       " 'say': 28755,\n",
       " 'such': 31180,\n",
       " 'doubts': 12166,\n",
       " 'reasonable': 27105,\n",
       " 'stand': 30621,\n",
       " 'convictions': 9817,\n",
       " 'electrical': 12746,\n",
       " 'eng': 13037,\n",
       " 'applied': 5287,\n",
       " 'physics': 25121,\n",
       " 'graduate': 15653,\n",
       " 'student': 31031,\n",
       " 'roboticist': 28207,\n",
       " 'training': 32709,\n",
       " 'wannabee': 34657,\n",
       " 'bullwinkle': 7412,\n",
       " 'intimidating': 18267,\n",
       " 'referee': 27307,\n",
       " 'very': 34229,\n",
       " 'doesn': 12052,\n",
       " 'look': 20470,\n",
       " 'jewish': 18779,\n",
       " 'carpenter': 7928,\n",
       " 'jodfishe': 18866,\n",
       " 'silver': 29706,\n",
       " 'ucs': 33213,\n",
       " 'indiana': 17687,\n",
       " 'joseph': 18929,\n",
       " 'dale': 10604,\n",
       " 'fisher': 14363,\n",
       " 'anger': 5030,\n",
       " '34': 2012,\n",
       " '17': 842,\n",
       " '44': 2258,\n",
       " '2232': 1512,\n",
       " 'news': 22944,\n",
       " 'cbnewsk': 8065,\n",
       " 'att': 5758,\n",
       " 'paul': 24616,\n",
       " 'conditt': 9428,\n",
       " 'insert': 18011,\n",
       " 'deletion': 11041,\n",
       " 'aaron': 3892,\n",
       " 'discourse': 11701,\n",
       " 'ref': 27304,\n",
       " 'galatians': 15060,\n",
       " '19': 966,\n",
       " '20': 1341,\n",
       " 'obvious': 23541,\n",
       " 'speaking': 30330,\n",
       " 'acts': 4211,\n",
       " 'flesh': 14440,\n",
       " 'just': 19076,\n",
       " 'emotions': 12902,\n",
       " 'themselves': 32163,\n",
       " 'moral': 22200,\n",
       " 'immoral': 17423,\n",
       " 'bad': 6057,\n",
       " 'first': 14357,\n",
       " 'label': 19649,\n",
       " 'emotion': 12898,\n",
       " 'numb': 23362,\n",
       " 'ourselves': 24050,\n",
       " 'hide': 16562,\n",
       " 'god': 15521,\n",
       " 'accepts': 4045,\n",
       " 'us': 33847,\n",
       " 'oh': 23660,\n",
       " 'definitely': 10983,\n",
       " 'colossians': 9056,\n",
       " 'ephesians': 13192,\n",
       " '27': 1700,\n",
       " 'controlled': 9774,\n",
       " 'puts': 26572,\n",
       " 'strong': 31000,\n",
       " 'emphasis': 12911,\n",
       " 'self': 29171,\n",
       " 'write': 35346,\n",
       " 'timothy': 32435,\n",
       " 'making': 20868,\n",
       " 'sure': 31394,\n",
       " 'teach': 31849,\n",
       " 'remainder': 27525,\n",
       " 'paragraph': 24411,\n",
       " 'think': 32253,\n",
       " 'quick': 26724,\n",
       " 'judge': 19014,\n",
       " 'forgiven': 14656,\n",
       " 'aids': 4566,\n",
       " 'dealt': 10802,\n",
       " 'taken': 31711,\n",
       " 'responsibility': 27840,\n",
       " 'appropriate': 5319,\n",
       " 'choices': 8499,\n",
       " 'read': 27049,\n",
       " 'yourself': 35651,\n",
       " 'joe': 18869,\n",
       " 'again': 4486,\n",
       " 'issue': 18542,\n",
       " 'especially': 13351,\n",
       " 'over': 24108,\n",
       " 'stem': 30741,\n",
       " 'instances': 18051,\n",
       " 'giving': 15408,\n",
       " 'soon': 30208,\n",
       " 'moore': 22193,\n",
       " 'aldridge': 4661,\n",
       " 'netcom': 22861,\n",
       " 'jacquelin': 18627,\n",
       " 'teenage': 31893,\n",
       " 'acne': 4165,\n",
       " 'line': 20242,\n",
       " 'communication': 9171,\n",
       " 'services': 29306,\n",
       " '408': 2198,\n",
       " '241': 1599,\n",
       " '9760': 3432,\n",
       " 'guest': 15907,\n",
       " 'pchurch': 24668,\n",
       " 'swell': 31528,\n",
       " 'actrix': 4210,\n",
       " 'gen': 15195,\n",
       " 'nz': 23432,\n",
       " 'pat': 24565,\n",
       " 'churchill': 8612,\n",
       " 'usual': 33889,\n",
       " 'spotty': 30494,\n",
       " 'chin': 8470,\n",
       " 'greasy': 15742,\n",
       " 'nose': 23240,\n",
       " 'bought': 7073,\n",
       " 'him': 16603,\n",
       " 'clearasil': 8777,\n",
       " 'face': 13892,\n",
       " 'wash': 34705,\n",
       " 'ointment': 23671,\n",
       " 'probably': 26085,\n",
       " 'diet': 11505,\n",
       " 'product': 26136,\n",
       " 'called': 7718,\n",
       " 'dalacin': 10602,\n",
       " 'used': 33860,\n",
       " 'prescription': 25907,\n",
       " 'treatment': 32847,\n",
       " 'available': 5906,\n",
       " 'chemist': 8406,\n",
       " 'counter': 10006,\n",
       " 'asked': 5580,\n",
       " 'couple': 10028,\n",
       " 'pharmacists': 24998,\n",
       " 'either': 12711,\n",
       " 'severe': 29337,\n",
       " 'ok': 23674,\n",
       " 'odd': 23589,\n",
       " 'spots': 30493,\n",
       " 'teenager': 31894,\n",
       " 'nothing': 23264,\n",
       " 'serious': 29285,\n",
       " 'father': 14060,\n",
       " 'figure': 14272,\n",
       " 'escalate': 13330,\n",
       " 'disfiguring': 11735,\n",
       " 'kids': 19336,\n",
       " 'senstitive': 29229,\n",
       " 'appearance': 5267,\n",
       " 'wary': 34702,\n",
       " 'neighbour': 22816,\n",
       " 'wierd': 35031,\n",
       " 'malady': 20873,\n",
       " 'eventually': 13501,\n",
       " 'down': 12176,\n",
       " 'overdose': 24121,\n",
       " 'vitamin': 34417,\n",
       " 'scaliness': 28779,\n",
       " 'around': 5489,\n",
       " 'hairline': 16038,\n",
       " 'scalp': 28783,\n",
       " 'sort': 30233,\n",
       " 'cradle': 10109,\n",
       " 'cap': 7820,\n",
       " 'pointers': 25445,\n",
       " 'advice': 4399,\n",
       " 'tried': 32898,\n",
       " 'anti': 5138,\n",
       " 'dandruff': 10633,\n",
       " 'shampoos': 29412,\n",
       " 'inclined': 17601,\n",
       " 'condition': 9423,\n",
       " 'worse': 35295,\n",
       " 'better': 6557,\n",
       " 'shall': 29399,\n",
       " 'bury': 7463,\n",
       " 'kid': 19330,\n",
       " 'till': 32409,\n",
       " '21': 1421,\n",
       " 'lucky': 20599,\n",
       " 'ones': 23746,\n",
       " 'little': 20342,\n",
       " 'luck': 20597,\n",
       " 'skin': 29864,\n",
       " 'gets': 15322,\n",
       " 'oily': 23668,\n",
       " 'really': 27088,\n",
       " 'miserable': 21898,\n",
       " 'pimples': 25200,\n",
       " 'dry': 12294,\n",
       " 'frequent': 14848,\n",
       " 'lukewarm': 20613,\n",
       " 'water': 34727,\n",
       " 'rinses': 28120,\n",
       " 'getting': 15323,\n",
       " 'thing': 32249,\n",
       " 'under': 33410,\n",
       " 'simple': 29724,\n",
       " 'submerging': 31093,\n",
       " 'bathwater': 6253,\n",
       " 'softened': 30112,\n",
       " 'washing': 34709,\n",
       " 'taking': 31716,\n",
       " 'mineral': 21814,\n",
       " 'heard': 16336,\n",
       " 'iodine': 18380,\n",
       " 'causes': 8037,\n",
       " 'trouble': 32962,\n",
       " 'fast': 14048,\n",
       " 'food': 14581,\n",
       " 'restaurants': 27850,\n",
       " 'sterilize': 30766,\n",
       " 'equipment': 13256,\n",
       " 'where': 34938,\n",
       " 'foods': 14583,\n",
       " 'came': 7746,\n",
       " 'grease': 15741,\n",
       " 'immediately': 17410,\n",
       " 'removed': 27567,\n",
       " 'eating': 12524,\n",
       " 'meat': 21356,\n",
       " 'keeping': 19213,\n",
       " 'hair': 16036,\n",
       " 'rinse': 28119,\n",
       " 'mousse': 22315,\n",
       " 'dip': 11599,\n",
       " 'spray': 30502,\n",
       " 'warm': 34672,\n",
       " 'bath': 6248,\n",
       " 'soaks': 30071,\n",
       " 'cloths': 8865,\n",
       " 'soften': 30111,\n",
       " 'oil': 23667,\n",
       " 'pores': 25580,\n",
       " 'prevent': 25983,\n",
       " 'blackheads': 6774,\n",
       " 'hydrophilic': 17093,\n",
       " 'loves': 20543,\n",
       " 'softens': 30113,\n",
       " 'washes': 34708,\n",
       " 'chance': 8278,\n",
       " 'goes': 15541,\n",
       " 'limp': 20226,\n",
       " 'oilyness': 23669,\n",
       " 'becoming': 6342,\n",
       " 'convinced': 9820,\n",
       " 'best': 6540,\n",
       " 'whitehead': 34973,\n",
       " 'leave': 19926,\n",
       " 'alone': 4787,\n",
       " 'days': 10760,\n",
       " 'pimple': 25199,\n",
       " 'misery': 21901,\n",
       " 'prying': 26386,\n",
       " 'black': 6773,\n",
       " 'whiteheads': 34974,\n",
       " 'infections': 17796,\n",
       " 'red': 27255,\n",
       " 'usually': 33891,\n",
       " 'break': 7167,\n",
       " 'naturally': 22686,\n",
       " 'won': 35217,\n",
       " 'infection': 17795,\n",
       " 'afterwards': 4479,\n",
       " 'normal': 23210,\n",
       " 'cosmetic': 9970,\n",
       " 'industry': 17742,\n",
       " 'makes': 20866,\n",
       " 'money': 22135,\n",
       " 'selling': 29180,\n",
       " 'idea': 17219,\n",
       " 'incredible': 17650,\n",
       " 'defect': 10949,\n",
       " 'hidden': 16561,\n",
       " 'cost': 9981,\n",
       " 'causing': 8039,\n",
       " 'jackie': 18618,\n",
       " 'geb': 15173,\n",
       " 'pitt': 25234,\n",
       " 'gordon': 15591,\n",
       " 'banks': 6140,\n",
       " 'blindsight': 6838,\n",
       " 'reply': 27664,\n",
       " 'pittsburgh': 25237,\n",
       " 'science': 28897,\n",
       " '18': 896,\n",
       " 'werner': 34881,\n",
       " '240393161954': 1594,\n",
       " 'tol7mac15': 32522,\n",
       " 'soe': 30105,\n",
       " 'berkeley': 6507,\n",
       " 'john': 18880,\n",
       " '19213': 995,\n",
       " 'uucp': 33940,\n",
       " 'wrote': 35363,\n",
       " 'explain': 13733,\n",
       " 'thought': 32298,\n",
       " 'types': 33142,\n",
       " 'cones': 9444,\n",
       " 'equivalent': 13259,\n",
       " 'rgb': 28011,\n",
       " 'basically': 6223,\n",
       " 'right': 28089,\n",
       " 'sensitive': 29222,\n",
       " 'green': 15755,\n",
       " 'blue': 6882,\n",
       " 'yellow': 35597,\n",
       " 'two': 33125,\n",
       " 'common': 9158,\n",
       " 'kinds': 19378,\n",
       " 'color': 9045,\n",
       " 'blindness': 6836,\n",
       " 'yes': 35601,\n",
       " 'remember': 27543,\n",
       " 'now': 23301,\n",
       " 'contrary': 9748,\n",
       " 'original': 23940,\n",
       " 'respondent': 27832,\n",
       " 'claimed': 8715,\n",
       " 'n3jxp': 22582,\n",
       " 'skepticism': 29848,\n",
       " 'chastity': 8362,\n",
       " 'intellect': 18117,\n",
       " 'cadre': 7665,\n",
       " 'dsl': 12307,\n",
       " 'shameful': 29408,\n",
       " 'surrender': 31424,\n",
       " 'too': 32570,\n",
       " 'libman': 20133,\n",
       " 'hsc': 16954,\n",
       " 'usc': 33853,\n",
       " 'marlena': 21053,\n",
       " 'patient': 24593,\n",
       " 'relationship': 27459,\n",
       " 'southern': 30259,\n",
       " 'california': 7711,\n",
       " 'los': 20506,\n",
       " 'angeles': 5026,\n",
       " 'ca': 7643,\n",
       " '64': 2667,\n",
       " 'situation': 29813,\n",
       " 'occurred': 23566,\n",
       " 'between': 6561,\n",
       " 'physican': 25115,\n",
       " 'upset': 33808,\n",
       " 'saw': 28747,\n",
       " 'recurring': 27248,\n",
       " 'pain': 24296,\n",
       " 'suggested': 31218,\n",
       " 'medication': 21389,\n",
       " 'course': 10037,\n",
       " 'told': 32523,\n",
       " 'begin': 6381,\n",
       " 'monitor': 22140,\n",
       " 'its': 18585,\n",
       " 'effectiveness': 12660,\n",
       " 'general': 15209,\n",
       " 'health': 16328,\n",
       " 'exactly': 13552,\n",
       " 'reaching': 27038,\n",
       " 'secretary': 29094,\n",
       " 'explained': 13737,\n",
       " 'her': 16470,\n",
       " 'following': 14565,\n",
       " 'request': 27727,\n",
       " 'worried': 35290,\n",
       " 'episodes': 13215,\n",
       " 'effective': 12658,\n",
       " 'words': 35249,\n",
       " 'whatever': 34924,\n",
       " 'busy': 7479,\n",
       " 'time': 32417,\n",
       " 'chit': 8493,\n",
       " 'chat': 8363,\n",
       " 'simply': 29736,\n",
       " 'instructions': 18080,\n",
       " '7th': 3052,\n",
       " 'status': 30696,\n",
       " 'feeling': 14137,\n",
       " 'talk': 31723,\n",
       " 'responded': 27831,\n",
       " 'spit': 30445,\n",
       " 'said': 28573,\n",
       " 'raised': 26849,\n",
       " 'voice': 34463,\n",
       " 'started': 30661,\n",
       " 'quickly': 26727,\n",
       " 'nervousness': 22847,\n",
       " 'interfered': 18176,\n",
       " 'choice': 8498,\n",
       " 'stuttered': 31052,\n",
       " ...}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that once we've fitted our vectorizer as we did above, we can use it's built-in dictionary to get the indices of any words we choose!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26727"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.vocabulary_.get('quickly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output above represents the index of the word \"dog\", not the actual count for how many times that word appears. However, we could use that index to look it up, if we chose to!\n",
    "\n",
    "Once we have our Count Vectorizer, it's pretty easy to leverage sklearn's `TfidfTransformer` to convert these counts to **_Term Frequencies_** (which is what the 'tf' in 'tf-idf' stands for). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_transformer = TfidfTransformer(use_idf=False).fit(x_train_counts)\n",
    "x_train_tf = tf_transformer.transform(x_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2257x35788 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 365886 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Our Classifier\n",
    "\n",
    "Now that we've vectorized our data, we can create a `MultinomialNB` classifier and fit it to our vectorized data!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(x_train_tf, twenty_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, we call `.fit()` and `.predict()` manually at first, so that we can change things around as needed experiment.  However, this can get a bit redundant--luckily, we can make use of sklearn's `Pipeline` class to automate many of the steps we've just done manually!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('count_vectorizer', CountVectorizer()), \n",
    "                     ('tfidf_vectorizer', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB())\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our pipeline object that contains the vectorization and transformation steps as well as our classifier, we can easily pass in unprocessed data and call things like `.fit()` and let the pipeline take care of all the steps we've outlined!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('count_vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       " ...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Classifier Performance \n",
    "\n",
    "Recall that in order to really get a feel for how well our classifier is performing, we need to check its performance against data it hasn't seen before. We do this by splitting off some of our labeled data into a **_Test Set_**.  We have already have a test set created thanks to the helper function that we used to load everything in. In the cell below, we'll use our pipeline object to create predictions.  We can then make use of the `metrics` module in sklearn to view a **_Classification Report_** that shows us how well our model performed! \n",
    "\n",
    "We'll start by loading in our test set, in the same way that we loaded in our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, \n",
    "                                 shuffle=True, random_state=0)\n",
    "test_articles = twenty_test.data\n",
    "test_labels = twenty_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function fetch_20newsgroups in module sklearn.datasets.twenty_newsgroups:\n",
      "\n",
      "fetch_20newsgroups(data_home=None, subset='train', categories=None, shuffle=True, random_state=42, remove=(), download_if_missing=True)\n",
      "    Load the filenames and data from the 20 newsgroups dataset (classification).\n",
      "    \n",
      "    Download it if necessary.\n",
      "    \n",
      "    =================   ==========\n",
      "    Classes                     20\n",
      "    Samples total            18846\n",
      "    Dimensionality               1\n",
      "    Features                  text\n",
      "    =================   ==========\n",
      "    \n",
      "    Read more in the :ref:`User Guide <20newsgroups_dataset>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    data_home : optional, default: None\n",
      "        Specify a download and cache folder for the datasets. If None,\n",
      "        all scikit-learn data is stored in '~/scikit_learn_data' subfolders.\n",
      "    \n",
      "    subset : 'train' or 'test', 'all', optional\n",
      "        Select the dataset to load: 'train' for the training set, 'test'\n",
      "        for the test set, 'all' for both, with shuffled ordering.\n",
      "    \n",
      "    categories : None or collection of string or unicode\n",
      "        If None (default), load all the categories.\n",
      "        If not None, list of category names to load (other categories\n",
      "        ignored).\n",
      "    \n",
      "    shuffle : bool, optional\n",
      "        Whether or not to shuffle the data: might be important for models that\n",
      "        make the assumption that the samples are independent and identically\n",
      "        distributed (i.i.d.), such as stochastic gradient descent.\n",
      "    \n",
      "    random_state : int, RandomState instance or None (default)\n",
      "        Determines random number generation for dataset shuffling. Pass an int\n",
      "        for reproducible output across multiple function calls.\n",
      "        See :term:`Glossary <random_state>`.\n",
      "    \n",
      "    remove : tuple\n",
      "        May contain any subset of ('headers', 'footers', 'quotes'). Each of\n",
      "        these are kinds of text that will be detected and removed from the\n",
      "        newsgroup posts, preventing classifiers from overfitting on\n",
      "        metadata.\n",
      "    \n",
      "        'headers' removes newsgroup headers, 'footers' removes blocks at the\n",
      "        ends of posts that look like signatures, and 'quotes' removes lines\n",
      "        that appear to be quoting another post.\n",
      "    \n",
      "        'headers' follows an exact standard; the other filters are not always\n",
      "        correct.\n",
      "    \n",
      "    download_if_missing : optional, True by default\n",
      "        If False, raise an IOError if the data is not locally available\n",
      "        instead of trying to download the data from the source site.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    bunch : Bunch object\n",
      "        bunch.data: list, length [n_samples]\n",
      "        bunch.target: array, shape [n_samples]\n",
      "        bunch.filenames: list, length [n_classes]\n",
      "        bunch.DESCR: a description of the dataset.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(fetch_20newsgroups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use our pipeline to create some predictions for our test data, and then compare the results to the corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8348868175765646"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = text_clf.predict(test_articles)\n",
    "\n",
    "# Mean of good predictions, stored as 1 or 0\n",
    "np.mean(test_predictions == test_labels) # Expected Output: 0.8348868175765646"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_83.4% accuracy--pretty good!_**  Let's round out this lab by viewing a full **_Classification Report_** for how our model performed for each given category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.97      0.60      0.74       319\n",
      "         comp.graphics       0.96      0.89      0.92       389\n",
      "               sci.med       0.97      0.81      0.88       396\n",
      "soc.religion.christian       0.65      0.99      0.78       398\n",
      "\n",
      "             micro avg       0.83      0.83      0.83      1502\n",
      "             macro avg       0.89      0.82      0.83      1502\n",
      "          weighted avg       0.88      0.83      0.84      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_labels, test_predictions, \n",
    "                              target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lesson, we worked through an example of how to use professional-quality tools such as **_sklearn_** to preprocess, vectorize, and classify real-world text data by predicting the categories of news articles using Naive Bayesian Classification. Great job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
